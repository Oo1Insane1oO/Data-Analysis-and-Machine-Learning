{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project on Machine Learning\n",
    "## Overview\n",
    "The aim of this project is to use data from Monte Carlo simulations of a familiar system from Statistical Mechanics, namely the Ising Model. We will use a simple model without any external magnetic field. The energy expectation value is expressed as\n",
    "    $$E=-J\\sum\\limits^N_{\\{kl\\}}s_ks_l$$\n",
    "The $s_k$ and $s_l$ indicate a spin. The spins are represented in a spin-lattice with $s_k=\\pm 1$ and $N$ being the total number of spins. $J$ is a coupling constant representing the strength of the interaction between neighbouring pairs of spins. The $<kl>$ notation indicate sum over the nearest neighbours.\n",
    "\n",
    "The data used is and the methods explored follow closesly article >> ref <<. The methods explored here is logistic regression, random forest algortihm and deep neural networks.\n",
    "\n",
    "The interresting physical properties to be extracted is states above, below and around a critical temperature $T_c$. When the system is in a temperature lower than this the system is in a so-called ferromagnetic phase. When close to the critical point, the magnetization becomes smaller, while the net magnetization is zero when the temperature is above $T_c$.\n",
    "\n",
    "## Theory\n",
    "We will first present the theory for the methods mentioned.\n",
    "\n",
    "### Linear Regression\n",
    "Linear regression model is a model for fitting data-points to a linear functional form.\n",
    "\n",
    "Given a data set \n",
    "    $$\\{y_i, \\boldsymbol{x}_i\\}_{i=1}^n,\\; i=1,\\dots,n$$ \n",
    "of $n$ points with $\\boldsymbol{X}$ being the $n\\times m$ matrix representing the regressors. Assuming the relationship between the regressors and $y_i$ is linear, the model is\n",
    "    $$\\boldsymbol{y} = \\boldsymbol{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}$$\n",
    "with \n",
    "    $$\n",
    "    \\boldsymbol{y} =\n",
    "        \\begin{pmatrix}\n",
    "            y_1 \\\\\n",
    "            \\vdots \\\\\n",
    "            y_n\n",
    "        \\end{pmatrix},\n",
    "    $$\n",
    "    $$\n",
    "    \\boldsymbol{X} =\n",
    "        \\begin{pmatrix}\n",
    "            1 & f_1\\left(x_{11}\\right) & \\dots & f_1\\left(x_{1m}\\right) \\\\\n",
    "            \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "            1 & f_n\\left(x_{n1}\\right) & \\dots & f_n\\left(x_{nm}\\right)\n",
    "        \\end{pmatrix}\n",
    "    $$\n",
    "and\n",
    "    $$\n",
    "    \\boldsymbol{\\beta} = \n",
    "        \\begin{pmatrix}\n",
    "            \\beta_0 \\\\\n",
    "            \\vdots \\\\\n",
    "            \\beta_m\n",
    "        \\end{pmatrix}.\n",
    "    $$\n",
    "The vector $\\boldsymbol{\\varepsilon}$ is an estimate for the noise in the system(i.e variance in the Monte Carlo simulation) and $f_i$ is a pre-defined function. This can for instance be a polynomial function\n",
    "    $$f_i(x) = x^i,$$\n",
    "or a polynomial in sine\n",
    "    $$f_i(x) = \\sin(ix),$$\n",
    "or any other suitable choice.\n",
    "\n",
    "The method of linear regression is simply to minimize the $L_2$-norm with respect to parameters $\\boldsymbol{\\beta}$, giving the following scheme\n",
    "    $$\\underset{\\boldsymbol{\\beta}}{\\text{min}}{\\big|}\\boldsymbol{X}\\boldsymbol{\\beta} - \\boldsymbol{y}{\\big|}^2,$$\n",
    "with solution\n",
    "    $$\\boldsymbol{\\beta}_{\\text{LS}} = \\underset{\\boldsymbol{\\beta}}{\\text{arg}\\text{min}}{\\big|}\\boldsymbol{X}\\boldsymbol{\\beta} - \\boldsymbol{y}{\\big|}^2.$$\n",
    "Some differentiation yields in the following solution\n",
    "    $$\\boldsymbol{\\beta}_{\\text{LS}} = \\left(\\boldsymbol{X}^T\\boldsymbol{X}\\right)^{-1}\\boldsymbol{X}^T\\boldsymbol{y}.$$\n",
    "This optimization is known as the least-squares scheme.\n",
    "\n",
    "#### Ridge and Lasso Regression\n",
    "While the linear regression model is rigorous and simple, it does have a tendency to overfit. In order to somewhat avoid this problem so-called regularization technicues have been developed. Two of these are Ridge and Lasso Regression.\n",
    "\n",
    "##### Ridge Regression\n",
    "With Ridge regression one performs an L2 regularization by adding an additional term equal to the square of the magnitude of the coefficients. This effectively ends up with performing the original linear regression, but with an added term. The equation is as follows\n",
    "    $$\\boldsymbol{y} = \\boldsymbol{X}\\boldsymbol{\\beta} + \\alpha\\sum_{i=1}^m\\beta^2_i,$$\n",
    "with the scheme\n",
    "    $$\\boldsymbol{\\beta}_{\\text{Ridge}} = \\underset{\\boldsymbol{\\beta}}{\\text{arg}\\text{min}}\\left({\\big|}\\boldsymbol{X}\\boldsymbol{\\beta} - \\boldsymbol{y}{\\big|}^2 + \\alpha{\\big|}\\boldsymbol{\\beta}{\\big|}^2\\right)$$\n",
    "The factor $\\alpha$ is just a scaling. This scheme is the same optimization problem as with the least-squares approach, but with a constraint $|\\boldsymbol{\\beta}|^2\\leq t$ for some $t\\geq 0$. We solve this again by differentiation with respect to $\\boldsymbol{\\beta}$ giving\n",
    "    $$\\boldsymbol{\\beta}_{\\text{Ridge}} = \\left(\\boldsymbol{X}^T\\boldsymbol{X} + \\alpha \\boldsymbol{I}\\right)^{-1}\\boldsymbol{X}^T\\boldsymbol{y}$$\n",
    "\n",
    "##### Lasso Regression\n",
    "The Lasso regression scheme performs an L1 regularization by adding only the absolute value of the magnitude of coefficients. The equation is\n",
    "    $$\\boldsymbol{y} = \\boldsymbol{X}\\boldsymbol{\\beta} + \\alpha\\sum_{i=1}^m{\\big|}\\beta_i{\\big|},$$\n",
    "with $\\alpha$ defined as before. The scheme is simply \n",
    "    $$\\boldsymbol{\\beta}_{\\text{Lasso}} = \\underset{\\boldsymbol{\\beta}}{\\text{arg}\\text{min}}\\left({\\big|}\\boldsymbol{X}\\boldsymbol{\\beta} - \\boldsymbol{y}{\\big|}^2 + \\alpha{\\big|}\\boldsymbol{\\beta}{\\big|}\\right).$$\n",
    "As with the Ridge scheme this is also an optimization similar to least-squares with a constraint. The constraint in this case is $|\\boldsymbol{\\beta}|\\leq t$ for some $t\\geq 0$.\n",
    "\n",
    "We cannot simply take the derivative in the Lasso scheme since the added regulizer is not everywhere differentiable, however since it is a convex problem the \"subgradient optimally condition\" can be invoked. Assuming $\\boldsymbol{X}$ is orthogonal the solution is\n",
    "    $$\\beta^{\\text{Lasso}}_j = \\text{sign}\\left(\\beta^{\\text{LS}}_j\\right)\\left({\\big|}\\beta^{\\text{LS}}_j{\\big|} - \\alpha\\right)_+$$\n",
    "\n",
    "#### Transform the Ising Model to a Linear Regression Problem\n",
    "In order to use linear regression with the Ising model we assume the model (without any prior knowledge) the all-to-all Ising model\n",
    "    $$E^{(i)} = -\\sum\\limits_{kl}^NJ_{kl}s^{(i)}_ks^{(i)}_l,$$\n",
    "with the $J_{kl}$ being the coupling strengths we wish to learn. The index $i$ represents a sample point. This equation can be rewritten as the matrix equation\n",
    "    $$E^{(i)} = -\\boldsymbol{X}^{(i)} \\cdot \\boldsymbol{J},$$\n",
    "with $\\boldsymbol{X}^{(i)}$ representing the two-body interactions \n",
    "    $$\\left\\{s^{(i)}_k,s^{(i)}_l\\right\\}_{k,l=1}^N.$$\n",
    "This is the exact linear regression presented earlier.\n",
    "\n",
    "### Logistic Regression\n",
    "As the title suggests, Logistic regression fits the data to a logistic function. A sigmoid function of the following form \n",
    "    $$f(x) = \\frac{1}{1 + \\exp(-\\boldsymbol{x}^T\\boldsymbol{w})}$$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd8HPWd//HXR922XJHcOy7YBmxAlFACBLCBH6GGBC4hEAhcckfKI+3gkuPHj8slIdylHhdCLoRUCCGBM8Egeo4SjA3GRS5YNsZVtmzZcpFV9/P7Y8fKelnZkryzs1q9n4/HPrQ7892Zz86O9r3zndkZc3dEREQA8qIuQEREsodCQURE2ikURESknUJBRETaKRRERKSdQkFERNopFEREpJ1CQUSygpkNNLM3zGyvmR0bdT29lUJBRLJFA/B/gEejLqQ3UygIZlZuZs+a2U4ze8DMvm1mX+zkc98wsxlprKXT885WufAauiPVutCV9cPdW9y9NpzqpLMUCgJwO7Da3QcD/wR8EvhpJ5/778Bd6SjCzMqT521mt5rZQjNrMrMH0zGfMKV6DV18/gQzeyoI6E1m9qn0Vhjq/FKtC2lbPyQzFAoCcD7wh+D+DcA8d9/fyefOBc41s+FpqCPVvDcD3wQe6OxEzOxOM7szDfV0xw10bfklexR4FigDbga+kaa6MjG/VOvCQcPMbLiZvZTilo71R9JAodCLmVmRmdUDxwFPmNlS4CLgLwltvmtmjyc8vsfMnjezIgB3bwTeBOakoaSD5h1M/0/u/jiwIw3Tb2dmI83sj2ZWa2bvmtnng+FHm1mdmZ2Y0K7WzM4JHq8zs9vNbHnw7foXZlZyqNfQhZqOB45y9++5e1swOLTulO7M71DrQ6p1IXmYu9e4+zkpbjXpfn3SPQqFXszdm4EPANvcvdTdjyMeEKsSmt1N/JveCWb2GeBC4MrguQesAGYmT9/M/mxmuzq4/TlFScnzDoWZ5QFPAIuBUcB5wBfNbI67ryHehfYbM+sL/AL4pbu/lDCJjxP/kDsamMLB366P5DWcAbxiZnlmdhLwPeAn3ZxWWPM73PqQal1IuX6kYmbzgNnAz8zshs69DEmngqgLkMjNIv7heMAgYM+BB+6+w8y+D/wSGAic6e71SdPYA4xInrC7X9LFWg6ad4hOBsrd/UBf91oz+xlwDVDp7j8zsw8D8wEHLk16/n+6+wYAM/s34Mf8LRiO5DXMAhYCLwIfBBYBjwXzuRs4HVgH3OjuLd2cR2fnN5B4t9J04DR3XwadWh9SrQsp149U3P3ibr8aSQttKUhyKOwE+ie1WUT8G/DtBz4Mk/QHdqWhllTz7pTErRLgNuC2Q2yVjANGJm65AP8MDEto8zPgWODH7t6U9PzEZfAeMPJQryHoM/cObq8kNJ0FLADOBSYBdcDdZjYTGOXuZwErgY+keP2dnUeilPMLxh3q8NBDrQ+p1oV0rR+SAQoFmcnBobCEeJcIAGZ2HPEuhV8CN3YwjWlJ0zjw3Kcs/kOkVLenUkznoHl3hbtf4u6D3H0Q8B3gOwcep9hi2QC8mzB+kLv3P/At1cxKgR8APwfuNLMhSc8fk3B/LPGd4R2+hqDP3Dq4nRnMM5/4clzk7rGgG+vVYBKnA88E958m3u2T/PoPO49Eh5lfh4eHdmJ9SLUupFw/JDspFCQ5FOYBZwOY2Sjife+fAf4BOO7ADtcDgp2sJxHvajiIu18U7KtIdbsoRS3t806YfkEwj3wg38xKzOxIuz3fAPaY2T+ZWR8zyzezY83s5GD8D4GF7v5p4EngvqTn/6OZjQ7C4uvA7w/1GjppKtAXuCioZxZwE/EP38HA7qBdPZAcUt1xqPmldLj1IdW6cKj1Q7KUu+vWS2/AcKAJKEwYVgZsJN5fvBj4fMK4rwCvJk3jauBPaarnwLz7JAy7k3i/fuLtzsNM585OtBkJPATUEO/yeZ34obmXAZuAIUG7UqAa+HjweB3x33UsJ94l8kug76FeQydf+8eJb2WsI94H/zbxHbgQ/wD+ZHD/JOL7NI50WXc4v6R2DxLvRhtwuPUh1bqQzvVDt8zcLHjjRNqZ2beIH5H0g060nQ/c5MGOyEzOOwpmtg74tLs/d4g2XX4NZnYPUOfu304xbhbwJXf/pJn9M/Gur4e6Xn3n5pfU7kHg3zvz/qZaF9K9fkj4FAoiXdCZUOjmdJ8jvgXweAfj7wFOA9YDn/KDDwlO+/yCNvOI74x+D/ipuz94JPOUnkGHpIpkh5nEjyxKyd2/msn5BfPU4aG9kLYURESknY4+EhGRdgoFERFp1+P2KZSVlfn48eOjLkNEpEd58803t7t7+eHa9bhQGD9+PAsXLoy6DBGRHsXM3utMO3UfiYhIO4WCiIi0UyiIiEg7hYKIiLRTKIiISLvQQsHMHjCzbWaW8kRYFvcjM6s2syUWXBNXRESiE+aWwoPEr9/akYuAycHtFsK9Fq2IiHRCaL9TcPf/NbPxh2hyGfArj5986XUzG2RmI9x9S1g1iUj2cHeaWmM0tcRobG2jqSVGayxGW8xpaXPaYt6pxzF33MGd+H0OXCcmfvGNWML9A8NTDXOcWMJ0UtV78OOk8e9rnzw+1TQPPY3kBudNG8bMMYPeN510ivLHa6M4+Fq3G4Nh7wsFM7uF+NYEY8eOzUhxItKxtphTt6+Z7XubqN3TxI59TdQ3tLCnsZU9Ta3saWxh9/5WdjfGhzU0t9LUGqOxpY3GlvjfptZY1C+jRzD72/2hA0pyOhQ6zd3vB+4HqKio0GldRULW3BrjvR37WF/XwIa6Bjbs3M/6ugY27txP7Z5G6vY1E+vgP7GkMI/+JYX0LylgQPB3+IASSgrzKCnMp6Qwn+KCPIoL8+PDCuLDigryKMw3CvLyyM8zCvKM/Hyj8MDjfGsfXpCXR0G+kWfxYQbkmWFGcEsaRjDMgmEktAvG5yWM58B47KDXZgc/TBobn96hx79/eSU/J2pRhsImDr4A+uhgmIhk0L6mVt7esIslG+tZWbObVTV7WFO7l5a2v33qlxTmMXZIX0YP7susMQMpKy2mvH8xZaUHbkUM6ltEaXEBRQU6qLEnizIU5gK3mtnDwKlAvfYniIRvX1Mrr1Rv57Xq7Sx8bycrtuxu/9Y/cmAJU4f355ypQ5k6vJRxR/VjzOC+lJUWZd03WglHaKFgZg8B5wBlZrYR+L9AIYC73wfMAy4mflH0BuBTYdUi0ttt3d3Ik0u28MLKbbzxbh3NbTH6FuUza8wgbj13EieNH8Ks0YMY2Lcw6lIlYmEefXTtYcY78I9hzV+kt2tobuWppTU8tmgTr67ZjjtMGlrKDWeM59ypQ6kYP5jCfHX1yMF6xI5mEem8LfX7+eVr7/HQG+up39/CmCF9+Ny5k7j8hFFMLC+NujzJcgoFkRyxcWcDP3xuNY8t2kTMnTkzhnPD6eM5ZcIQ7Q+QTlMoiPRwO/c188PnV/O7+evB4BOnjeOmMycwZkjfqEuTHkihINJDuTuPvrmRb81bwe7GVj5aMZrPnzeZEQP7RF2a9GAKBZEeaENdA1/5w2Lmv1tHxbjB/NsVxzF1eP+oy5IcoFAQ6WHmLt7M1/+0FIDvXHkcH60YQ16e9hlIeigURHqIlrYYd86t4rfz13Pi2EH88JoTtN9A0k6hINID7NzXzGd/+yavr63j78+eyFdnT6VAvzGQECgURLLchroGrvv5fDbXN/L9j83kihNGR12S5DCFgkgWq962l0/893z2t7Tx0M2ncdK4wVGXJDlOoSCSpVbV7OHvfvY6ZvDwLacxbcSAqEuSXkChIJKF1u+IdxkV5BsP3XyaTk8hGaNQEMky2/Y0ct0D82lui/HI339AgSAZpcMXRLLI/uY2PvWLBdTuaeIXN5zMlGH6QZpklrYURLKEu/PVRxezfMtuHrj+ZE4Yq53KknnaUhDJEj/5yxr+vGQLX5tzDOceMzTqcqSXUiiIZIGXV9dyT+UqPjxzJJ85e2LU5UgvplAQidiOvU186ZHFTCov5btXHa9rH0iktE9BJELuztceXUL9/hZ+deMp9CnKj7ok6eW0pSASod+8/h7Pr9zG7Rcdox+nSVZQKIhEZOPOBr791Eo+OKWcG04fH3U5IoBCQSQS7s43Hl8GwLevPE77ESRrKBREIjB38WZeWlXLV2ZPZdQgXT5TsodCQSTD6htauOuJ5cwcM4jr1W0kWUahIJJhP3x+NTsbmvnWFceSr8toSpZRKIhk0Jravfzqr+v42MljmTFyYNTliLyPQkEkg7715ApKCvP58uwpUZcikpJCQSRDXl5dy/Mrt/G5D02irLQ46nJEUlIoiGSAu3P30ysZM6QPN5wxPupyRDqkUBDJgMqqrSzbtJsvnDeF4gKdykKyl0JBJGSxmPP9Z99hYnk/Lp81MupyRA4p1FAwswvNbJWZVZvZbSnGjzWzF81skZktMbOLw6xHJAp/XrqFVVv38MXzp1CQr+9hkt1CW0PNLB+4F7gImA5ca2bTk5p9A3jE3U8ArgH+K6x6RKLQFnN+8Nw7TB3Wn0uOGxF1OSKHFebXllOAandf6+7NwMPAZUltHDhwasiBwOYQ6xHJuKeX1bC2dh9fOH8yefqhmvQAYYbCKGBDwuONwbBEdwKfMLONwDzgc6kmZGa3mNlCM1tYW1sbRq0iaefu3PeXNUwo68ecGcOjLkekU6Lu4LwWeNDdRwMXA782s/fV5O73u3uFu1eUl5dnvEiR7nhtzQ6Wbqrnlg9O1OkspMcIMxQ2AWMSHo8OhiW6CXgEwN3/CpQAZSHWJJIxP3lpDeX9i7nihOQNZJHsFWYoLAAmm9kEMysiviN5blKb9cB5AGY2jXgoqH9Ierxlm+p5pXo7N54xgZJC/S5Beo7QQsHdW4FbgUpgBfGjjKrM7C4zuzRo9mXgZjNbDDwE3ODuHlZNIpny81fepbS4gI+fNjbqUkS6pCDMibv7POI7kBOH3ZFwfzlwRpg1iGRa7Z4mnlyyhb87dSwDSgqjLkekS6Le0SyScx5+Yz3NbTGu+8C4qEsR6TKFgkgatbTF+O389Zw1uYyjy0ujLkekyxQKImn07PKt1Oxu5PoPjI+6FJFuUSiIpNGDr61j9OA+nHvM0KhLEekWhYJImqyq2cMb79bxyQ+M04/VpMdSKIikycML1lOUn8dHThpz+MYiWUqhIJIGTa1tPLZoExfMGMaQfkVRlyPSbQoFkTR4pmoruxpa+FiFthKkZ1MoiKTBIws3MGpQH86cpFN3Sc+mUBA5QhvqGnh59XaurhitayZIj6dQEDlCf3hzI2ZwtbqOJAcoFESOQCzmPLpwA2dNLmfUoD5RlyNyxBQKIkdg/rt1bK5v5KoTdc0EyQ0KBZEj8D9vb6JfUT6zp+tym5IbFAoi3dTY0saTS7cw59jh9CnShXQkNygURLrppVXb2NPYyuWz1HUkuUOhINJNjy3aRHn/Yk4/+qioSxFJG4WCSDfUN7Tw4spaPnz8SAry9W8kuUNrs0g3zFu2hea2GFecoK4jyS0KBZFueHzRJiaW9+PYUQOiLkUkrRQKIl20add+5r9bxxWzRmGm01pIblEoiHTRU0u3AHDprJERVyKSfgoFkS6qrKrhmOH9GXdUv6hLEUk7hYJIF9TuaWLhezuZM0O/YJbcpFAQ6YLnVmzFHYWC5CyFgkgXVFbVMGZIH6aN6B91KSKhUCiIdNKexhZeq97BnOnDddSR5CyFgkgnvbiqlua2GHOOVdeR5C6FgkgnVVbVUFZaxIljB0ddikhoFAoindDY0sZLK7dxwfRh5Os6zJLDQg0FM7vQzFaZWbWZ3dZBm4+a2XIzqzKz34VZj0h3vbZmO/ua25ito44kxxWENWEzywfuBS4ANgILzGyuuy9PaDMZuB04w913mtnQsOoRORKVy7ZSWlyg02RLzgtzS+EUoNrd17p7M/AwcFlSm5uBe919J4C7bwuxHpFuaYs5z63YyrnHDKW4QFdYk9wWZiiMAjYkPN4YDEs0BZhiZq+a2etmdmGqCZnZLWa20MwW1tbWhlSuSGoL19WxY18zc2YMi7oUkdBFvaO5AJgMnANcC/zMzAYlN3L3+929wt0rysvLM1yi9HaVVVspKsjjnKnq3ZTcF2YobALGJDweHQxLtBGY6+4t7v4u8A7xkBDJCu5OZVUNZ04qo7Q4tF1wIlkjzFBYAEw2swlmVgRcA8xNavM48a0EzKyMeHfS2hBrEumSqs272bRrv7qOpNcILRTcvRW4FagEVgCPuHuVmd1lZpcGzSqBHWa2HHgR+Kq77wirJpGueqaqhjyD86cpFKR3CHV72N3nAfOSht2RcN+BLwU3kaxTWbWVivFDOKq0OOpSRDIi6h3NIllr3fZ9rNq6R6fJll5FoSDSgcqqGgBmT1fXkfQeCgWRDlRW1TBj5ADGDOkbdSkiGaNQEElh2+5G3lq/S11H0usoFERSeGb5VkCX3ZTeR6EgkkJlVQ3jj+rLlGGlUZciklEKBZEk9ftb+OuaHcyZoctuSu+jUBBJ8uLKbbTGXNdOkF6pUz9eC65zcAYwEtgPLAMWunssxNpEIlFZVcPQ/sWcMOZ952YUyXmHDAUzOxe4DRgCLAK2ASXA5cDRZvYo8B/uvjvsQkUyobGljZdW1XLliaPI02U3pRc63JbCxcDN7r4+eYSZFQCXEL+y2h9DqE0k415evZ39LW066kh6rUOGgrt/9RDjWomf5VQkZ1RW1TCgpIDTJuqym9I7dWpHs5n92swGJjweb2bPh1eWSOa1tsV4fsVWzps2jKICHYMhvVNn1/xXgPlmdrGZ3Qw8A/wgvLJEMu+NdXXsbGjRtROkV+vU0Ufu/lMzqyJ+zYPtwAnuXhNqZSIZ9kzVVooL8vjgFF3yVXqvznYfXQc8AHwSeBCYZ2YzQ6xLJKPcnWeqavjglHL6Fumym9J7dbb76CrgTHd/yN1vBz5DPBxEcsLSTfVsrm/UUUfS63W2++jypMdvmNmp4ZQkknmVVTXk5xnnTxsadSkikTrkloKZfcPMhqQa5+7NZvYhM7sknNJEMqeyaiunThjCoL5FUZciEqnDbSksBZ4ws0bgLaCW+C+aJwOzgOeAb4VaoUjI1tTupXrbXq47bVzUpYhE7nCh8BF3P8PMvkb8FBcjgN3Ab4Bb3H1/2AWKhK39sps6FFXksKFwkpmNBD4OnJs0rg/xk+OJ9GiVVVuZOXogIwb2iboUkcgdLhTuA54HJgILE4Yb4MFwkR6rpr6RxRt28dU5U6MuRSQrHHJHs7v/yN2nAQ+4+8SE2wR3VyBIj/fM8njXkQ5FFYnr1O8U3P2zYRciEoXKqhqOLu/HpKG67KYI6Mpr0ovtamjm9bV12koQSaBQkF7r+RXbaIu5QkEkgUJBeq2nq2oYMbCE40cPPHxjkV5CoSC9UkNzKy+vrmX29GGY6bKbIgcoFKRX+suqWhpbYsw5Vl1HIokUCtIrPbWshiH9ijhlfMpTe4n0WqGGgpldaGarzKzazG47RLurzMzNrCLMekQAmlrbeGHlNi6YNoyCfH0vEkkU2n+EmeUD9wIXAdOBa81seop2/YEvAPPDqkUk0avV29nb1MqFx6nrSCRZmF+TTgGq3X2tuzcDDwOXpWj3r8DdQGOItYi0e3pZDf2LCzj96KOiLkUk64QZCqOADQmPNwbD2pnZicAYd3/yUBMys1vMbKGZLaytrU1/pdJrtLbFeHb5Vs6bNpTigvyoyxHJOpF1qJpZHvA94MuHa+vu97t7hbtXlJfrourSfW+8W8fOhhYu1FFHIimFGQqbgDEJj0cHww7oDxwLvGRm64DTgLna2SxherqqhpLCPM6eostuiqQSZigsACab2QQzKwKuAeYeGOnu9e5e5u7j3X088DpwqbsvTD05kSMTizlPL6vhnClD6VOkriORVEILBXdvBW4FKoEVwCPuXmVmd5nZpWHNV6QjizbsYtueJi7SUUciHTrcRXaOiLvPA+YlDbujg7bnhFmLyNPLtlCYb5x7jLqORDqiX+5Ir+DuPLWshjMmlTGgpDDqckSylkJBeoXFG+vZuHM/lxw/MupSRLKaQkF6hScWb6YoP4/ZM4ZFXYpIVlMoSM6LxZw/L9nM2VPL1XUkchgKBcl5C9bVsXV3Ex+eqa4jkcNRKEjOe2LJZvoU5nP+NB11JHI4CgXJaa1tMeYtreG8aUPpWxTqEdgiOUGhIDnttTU7qNvXrKOORDpJoSA57YnFmyktLuCcqTqRokhnKBQkZzW1tlFZVcPsGcMoKdS5jkQ6Q6EgOeulVbXsbmzVUUciXaBQkJz1xzc3UlZazFmTyqIuRaTHUChITqrb18yLq7Zx+ayRFORrNRfpLP23SE56YvFmWtqcq04aHXUpIj2KQkFy0h/f2sj0EQOYNmJA1KWI9CgKBck5q7fuYcnGeq48cVTUpYj0OAoFyTmPvrWR/DzjslkKBZGuUihITmmLOY8v2sQ5U8op718cdTkiPY5CQXLKK9Xb2bq7STuYRbpJoSA55Xfz32NIvyLO0xlRRbpFoSA5Y+vuRp5bsY2rK0ZTXKDTWoh0h0JBcsbvF2ygLeZce/LYqEsR6bEUCpIT2mLOw2+s58xJZYwv6xd1OSI9lkJBcsJf3tnG5vpG/u5UbSWIHAmFguSE381fT1lpMRdMHxZ1KSI9mkJBerwNdQ28sHIbH60YTaFOfidyRPQfJD3eL19bR54Z131gXNSliPR4CgXp0fY2tfL7BRu4+LgRjBjYJ+pyRHo8hYL0aH9YuIE9Ta3ceOaEqEsRyQkKBemx2mLOL15dx0njBjNrzKCoyxHJCaGGgpldaGarzKzazG5LMf5LZrbczJaY2fNmpk5h6bTnVmxlfV0DN56hrQSRdAktFMwsH7gXuAiYDlxrZtOTmi0CKtz9eOBR4Lth1SO5xd35r5fWMGZIH+bM0GGoIukS5pbCKUC1u69192bgYeCyxAbu/qK7NwQPXwd0akvplFeqt7N4wy4+e/YkXYNZJI3C/G8aBWxIeLwxGNaRm4CnUo0ws1vMbKGZLaytrU1jidJT/fiFaoYPKOGqk3QhHZF0yoqvWGb2CaACuCfVeHe/390r3L2ivLw8s8VJ1nnj3TreeLeOvz97os6GKpJmBSFOexMwJuHx6GDYQczsfODrwNnu3hRiPZIjfvzCaspKi7hGZ0MVSbswtxQWAJPNbIKZFQHXAHMTG5jZCcBPgUvdfVuItUiOmL92By+v3s7NZ02kT5G2EkTSLbRQcPdW4FagElgBPOLuVWZ2l5ldGjS7BygF/mBmb5vZ3A4mJ4K7852nVzJsQDHXnz4+6nJEclKY3Ue4+zxgXtKwOxLunx/m/CW3PLt8K4vW7+LbVx5HSaG2EkTCkBU7mkUOpy3m3FO5ioll/bj6JB25LBIWhYL0CI8s3MDqbXv5ypyp+l2CSIj03yVZb1dDM999eiUnjx/MRccOj7ockZymUJCs971n36F+fwv/79JjMbOoyxHJaQoFyWpVm+v5zevvcd1p45g+ckDU5YjkPIWCZK22mPMvjy9jcN8ivjR7atTliPQKCgXJWr949V3eWr+Lb1wyjYF9CqMuR6RXUChIVlpTu5d7Kldx/rRhXD5LJ70TyRSFgmSdtpjztUeXUFKYz7eu0M5lkUwK9RfNIt3x4xdW8+Z7O/nBx2YxdEBJ1OWI9CraUpCs8lr1dn74/GquPHEUl80aGXU5Ir2OQkGyxrY9jXz+4bc5uryUb16ubiORKKj7SLJCU2sb//jbt9jb1MJvP30qfYu0aopEQf95Ejl357Y/LmXBup386NoTmDq8f9QlifRa6j6SyP3o+WoeW7SJL18whUtnaj+CSJQUChKpX7/+Ht9/7h2uPGEUt35oUtTliPR6CgWJzCMLNvAvjy/jvGOG8p2rjteOZZEsoFCQSPxh4Qb+6U9LOGtyGfd+/ESKCrQqimQD7WiWjHJ37vvLWu5+eiVnTirj/usqdGlNkSyiUJCMaW2L8c0nV/Dga+u4dOZI/v3qmdpCEMkyCgXJiO17m/jc7xbx17U7uOnMCXz94mnk5Wkfgki2UShI6Oav3cEXf/82dfua+Y+rZ3LVSaOjLklEOqBQkNA0trRxT+UqHnj1XcYM7ssfP3s6x44aGHVZInIICgUJxf++U8udc6tYu30f1502jtsuOoZ+xVrdRLKd/kslrdbW7uXfnlzB8yu3Me6ovvzmplM5c3JZ1GWJSCcpFCQt3tm6h3tfrOaJxZvpW1TA7Rcdww1njKe4QIebivQkCgXptljMebl6O795/T2eXb6VvkX53HzWRD591kTK+xdHXZ6IdINCQbpsbe1enlyyhUfe3MCGuv0M6VfE5z80iU+dMYHB/YqiLk9EjoBCQQ6rLeYs21TPS6tqeWrZFlbW7AHgtIlD+OqcY5gzY5i6iURyhEJB3qeptY0VW/aweMMu/rpmB6+t2c7uxlbMoGLcYO64ZDoXHjuckYP6RF2qiKSZQqEXi8WcTbv2s6Z2L2tr97F6216WbtrFqpo9tLQ5AKMG9eHCY4dzxqQyTj+6TPsKRHJcqKFgZhcCPwTygf929+8kjS8GfgWcBOwAPubu68Ksqbdoam2jvqGFnQ0tbNvTyJb6RmrqG9lSv58t9Y1s2dXIuh37aGqNtT9nQEkBx40eyKfPmsjxowZy/JhBjBxYolNai/QioYWCmeUD9wIXABuBBWY2192XJzS7Cdjp7pPM7BrgbuBjYdUUJXenpc1pjcVoaXNa2mK0Hvgbc1rbYgeNbw2GN7W2sb85RkNzK/tb2tjf3EZDcxv7W9riw4Jx9fvjAVDf0MzOhhb2t7SlrKOstIjhA0sYM6QvH5xSxsTyUiaW9ePooaUc1a9IASDSy4W5pXAKUO3uawHM7GHgMiAxFC4D7gzuPwr8p5mZu3u6i3lkwQbuf3kt7o47OPEP6piDEwzz+DAHYkntDtxvH3646QT3Y8H00v2KSgrz6FtUQJ/CfPoW5TOwTyGjBvVhxsgBDO5byKC+RQzsU8igvoUM7V/CiIElDB1QrB3CInJIYYbCKGBDwuONwKkdtXH3VjOrB44Ctic2MrOCeKP5AAAHsUlEQVRbgFsAxo4d261iBvUtZMqwUswMi0+TPKP9vhkY8b95Cff/Ng7yEu4nPifPSGr7/unkmVGYbxTk51GQZxTm51GQH/9bmG8U5P3t74HhBXlGUUH8w79vUT59iuIBUFKQrzOMikgoesSOZne/H7gfoKKiolvfuWfPGM7sGcPTWpeISK4J8wonm4AxCY9HB8NStjGzAmAg8R3OIiISgTBDYQEw2cwmmFkRcA0wN6nNXOD64P5HgBfC2J8gIiKdE1r3UbCP4FagkvghqQ+4e5WZ3QUsdPe5wM+BX5tZNVBHPDhERCQioe5TcPd5wLykYXck3G8Erg6zBhER6TxdNV1ERNopFEREpJ1CQURE2ikURESknfW0I0DNrBZ4r5tPLyPp19JZQnV1jerqumytTXV1zZHUNc7dyw/XqMeFwpEws4XuXhF1HclUV9eorq7L1tpUV9dkoi51H4mISDuFgoiItOttoXB/1AV0QHV1jerqumytTXV1Teh19ap9CiIicmi9bUtBREQOQaEgIiLtci4UzOxqM6sys5iZVSSNu93Mqs1slZnN6eD5E8xsftDu98Fpv9Nd4+/N7O3gts7M3u6g3TozWxq0W5juOlLM704z25RQ28UdtLswWIbVZnZbBuq6x8xWmtkSM3vMzAZ10C4jy+twr9/MioP3uDpYl8aHVUvCPMeY2YtmtjxY/7+Qos05Zlaf8P7ekWpaIdR2yPfF4n4ULK8lZnZiBmqamrAc3jaz3Wb2xaQ2GVteZvaAmW0zs2UJw4aY2bNmtjr4O7iD514ftFltZtenatMl8WsN584NmAZMBV4CKhKGTwcWA8XABGANkJ/i+Y8A1wT37wM+G3K9/wHc0cG4dUBZBpfdncBXDtMmP1h2E4GiYJlOD7mu2UBBcP9u4O6olldnXj/wD8B9wf1rgN9n4L0bAZwY3O8PvJOirnOAP2dqfers+wJcDDxF/Eq3pwHzM1xfPlBD/MddkSwv4IPAicCyhGHfBW4L7t+War0HhgBrg7+Dg/uDj6SWnNtScPcV7r4qxajLgIfdvcnd3wWqgVMSG5iZAR8CHg0G/RK4PKxag/l9FHgorHmE4BSg2t3Xunsz8DDxZRsad3/G3VuDh68Tv4pfVDrz+i8jvu5AfF06L3ivQ+PuW9z9reD+HmAF8Wug9wSXAb/yuNeBQWY2IoPzPw9Y4+7dPVPCEXP3/yV+TZlEietRR59Fc4Bn3b3O3XcCzwIXHkktORcKhzAK2JDweCPv/6c5CtiV8AGUqk06nQVsdffVHYx34Bkze9PMbgmxjkS3BpvwD3SwudqZ5RimG4l/q0wlE8urM6+/vU2wLtUTX7cyIuiuOgGYn2L0B8xssZk9ZWYzMlTS4d6XqNepa+j4i1kUy+uAYe6+JbhfAwxL0Sbtyy7Ui+yExcyeA4anGPV1d/+fTNeTSidrvJZDbyWc6e6bzGwo8KyZrQy+UYRSF/AT4F+J/xP/K/GurRuPZH7pqOvA8jKzrwOtwG87mEzal1dPY2alwB+BL7r77qTRbxHvItkb7C96HJicgbKy9n0J9hleCtyeYnRUy+t93N3NLCO/H+iRoeDu53fjaZuAMQmPRwfDEu0gvulaEHzDS9UmLTWaWQFwJXDSIaaxKfi7zcweI951cUT/TJ1ddmb2M+DPKUZ1ZjmmvS4zuwG4BDjPg87UFNNI+/JKoTOv/0CbjcH7PJD4uhUqMyskHgi/dfc/JY9PDAl3n2dm/2VmZe4e6onfOvG+hLJOddJFwFvuvjV5RFTLK8FWMxvh7luC7rRtKdpsIr7v44DRxPendltv6j6aC1wTHBkygXjiv5HYIPiweRH4SDDoeiCsLY/zgZXuvjHVSDPrZ2b9D9wnvrN1Waq26ZLUj3tFB/NbAEy2+FFaRcQ3veeGXNeFwNeAS929oYM2mVpenXn9c4mvOxBfl17oKMjSJdhn8XNghbt/r4M2ww/s2zCzU4j//4caVp18X+YCnwyOQjoNqE/oNglbh1vrUSyvJInrUUefRZXAbDMbHHT3zg6GdV8m9qxn8kb8w2wj0ARsBSoTxn2d+JEjq4CLEobPA0YG9ycSD4tq4A9AcUh1Pgh8JmnYSGBeQh2Lg1sV8W6UsJfdr4GlwJJghRyRXFfw+GLiR7esyVBd1cT7Td8Obvcl15XJ5ZXq9QN3EQ8tgJJg3akO1qWJGVhGZxLv9luSsJwuBj5zYD0Dbg2WzWLiO+xPz0BdKd+XpLoMuDdYnktJOGow5Nr6Ef+QH5gwLJLlRTyYtgAtwefXTcT3Qz0PrAaeA4YEbSuA/0547o3BulYNfOpIa9FpLkREpF1v6j4SEZHDUCiIiEg7hYKIiLRTKIiISDuFgoiItFMoiIhIO4WCiIi0UyiIHCEzOzk4iWBJ8AveKjM7Nuq6RLpDP14TSQMz+ybxXzL3ATa6+7cjLkmkWxQKImkQnAdpAdBI/HQIbRGXJNIt6j4SSY+jgFLiVz0ribgWkW7TloJIGpjZXOJXYZtA/ESCt0Zckki39MjrKYhkEzP7JNDi7r8zs3zgNTP7kLu/EHVtIl2lLQUREWmnfQoiItJOoSAiIu0UCiIi0k6hICIi7RQKIiLSTqEgIiLtFAoiItLu/wOPioqXkHbL3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def logisticFunction(x, b0=1, b1=1):\n",
    "    \"\"\" calculate and return logistic function \"\"\"\n",
    "    return 1 / (1 + np.exp(-b0-b1*x))\n",
    "\n",
    "x = np.linspace(-10,10,1000)\n",
    "\n",
    "plt.plot(x, logisticFunction(x))\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.title(\"$f(x)=(1 + \\\\exp(-\\\\beta_0-\\\\beta_1x))^{-1}$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea with the binary logistic regression is to find the probability for a stochastic variable $X$ to be part of some category $Y$, this is just a joint probability $P(Y|X)$. In terms of regression terminology $Y$ would be the response and $X$ the explanatory variable. $X$ can be a data-point and the categories can be expressed as $Y=\\{0,1\\}$. Since we work with data-points it is convenient to index them as\n",
    "    $$X\\rightarrow X_i$$\n",
    "    $$Y\\rightarrow Y_i=\\{0,1\\}$$\n",
    "The probabilites can then be expressed as\n",
    "    $$f(Y_i=1|\\boldsymbol{X}_i,\\boldsymbol{w}) = \\frac{1}{1 + \\exp(-\\boldsymbol{X}_i^T\\boldsymbol{w})}$$\n",
    "    $$f(Y_i=0|\\boldsymbol{X}_i,\\boldsymbol{w}) = 1 - f(Y_i=1|\\boldsymbol{X}_i)$$\n",
    "The problem addressed is simply a dataset with points $\\boldsymbol{X}_i$ and binary labels $Y_i\\in\\{0,1\\}$. Considering drawing datapoints independently the likelihood of seing some data $D_i=\\{(Y_i,\\boldsymbol{X}_i)\\}$ is\n",
    "    $$P(D_i|\\boldsymbol{w}) = \\prod_{i=1}^n\\left[f\\left(\\boldsymbol{X}_i^T\\boldsymbol{w}\\right)\\right]^{Y_i} \\left[1 - f\\left(\\boldsymbol{X}_i^T\\boldsymbol{w}\\right)\\right]^{1-Y_i},$$\n",
    "and the maximum likelihood estimator(MLE) is defined as the set of parameters which maximizes the log-likelihood(log of above function). The expression for $\\boldsymbol{w}$ is\n",
    "    $$\\boldsymbol{w}_{\\text{MLE}}= \\underset{\\boldsymbol{w}}{\\text{arg}\\text{max}} \\sum\\limits_{i=1}^n \\left[y_i\\log\\left(f\\left(\\boldsymbol{X}_i^T\\boldsymbol{w}\\right)\\right) + (1 - Y_i)\\log\\left(1 - f\\left(\\boldsymbol{X}_i^T\\boldsymbol{w}\\right)\\right)\\right].$$\n",
    "The cost is just the negative log-likelihood and is known as the cross-entropy in statistics. The expression is\n",
    "    $$C(\\boldsymbol{w}) = -\\sum\\limits_{i=1}^n \\left[Y_i\\log\\left(f\\left(\\boldsymbol{X}_i^T\\boldsymbol{w}\\right)\\right) + (1 - Y_i)\\log\\left(1 - f\\left(\\boldsymbol{X}_i^T\\boldsymbol{w}\\right)\\right)\\right].$$\n",
    "The cross-entropy is convex by the second-derivative test(with respect to parameters $\\boldsymbol{w}$) meaning a simple minimization gives the global minimum. The equation is\n",
    "    $$\\boldsymbol{0} = \\nabla C(\\boldsymbol{w}) = \\sum_{i=1}^n\\left[f\\left(\\boldsymbol{X}_i^T\\boldsymbol{w}\\right) - Y_i\\right]\\boldsymbol{X}_i.$$\n",
    "This is a transcendental equation for $\\boldsymbol{w}$ which has to be solved numerically by some numerical optimization scheme such as gradient descent or some Quasi-Newton method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
